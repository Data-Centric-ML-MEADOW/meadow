{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/955923/ipykernel_956527/2969469411.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# All imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "csv_dir = \"/home/hice1/kkang68/scratch/meadow/results/\"\n",
    "# List of provided filenames\n",
    "resnet_results = [\n",
    "    \"resnet-152_20241103-174623_lr0.0001_bs64.csv\",\n",
    "    \"resnet-50_20241107-111821_lr0.0001_bs64.csv\",\n",
    "    \"resnet-34_20241114-123531_lr1.00e-04_bs128[e40estop7].csv\",\n",
    "]\n",
    "\n",
    "snapshot_ensemble_results = [\n",
    "    \"resnet-50_20241114-232226_lr2.00e-01_bs128_snapshot-pl5[e40].csv\",\n",
    "    \"resnet-50_20241118-130313_lr2.00e-01_bs128_snapshot-pl3[e60].csv\",\n",
    "    \"resnet-34_20241113-212612_lr2.00e-01_bs128_snapshot-pl5[e40].csv\",\n",
    "    \"resnet-34_20241116-174004_lr2.00e-01_bs128_snapshot-pl3[e60].csv\",\n",
    "]\n",
    "\n",
    "moe_results = [\n",
    "    \"MoE3_resnet-50_resnet-domain-50_20241118-081710_lr1.00e-04_bs128[snap-5_lexp-3-learnMapper].csv\",\n",
    "    \"MoE5_resnet-34_resnet-domain-50_20241116-130542_lr1.00e-03_bs128[learnAllSteep-reworkForward-smaxRouter].csv\",\n",
    "    \"MoE5_resnet-50_resnet-domain-50_20241118-152917_lr1.00e-04_bs128[snap-5_lexp-3_learnMapper_uniformInit].csv\",\n",
    "]\n",
    "\n",
    "vit_results = [\n",
    "    \"vit-16_20241113-204439_lr1.00e-04_bs64[nofreeze].csv\",\n",
    "    \"vit-16_20241116-165014_lr1.00e-04_bs64[freeze].csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet Results:\n",
      "1. File: resnet-50_20241107-111821_lr0.0001_bs64.csv, Test Accuracy: 0.738192617893219, Test ID Accuracy: 0.7257787585258484\n",
      "2. File: resnet-152_20241103-174623_lr0.0001_bs64.csv, Test Accuracy: 0.7211329340934753, Test ID Accuracy: 0.7267598509788513\n",
      "3. File: resnet-34_20241114-123531_lr1.00e-04_bs128[e40estop7].csv, Test Accuracy: 0.6820592880249023, Test ID Accuracy: 0.6802796125411987\n",
      "\n",
      "Snapshot Ensemble Results:\n",
      "1. File: resnet-50_20241114-232226_lr2.00e-01_bs128_snapshot-pl5[e40].csv, Test Accuracy: 0.6775256395339966, Test ID Accuracy: 0.7010056376457214\n",
      "2. File: resnet-50_20241118-130313_lr2.00e-01_bs128_snapshot-pl3[e60].csv, Test Accuracy: 0.6773152947425842, Test ID Accuracy: 0.7011283040046692\n",
      "3. File: resnet-34_20241113-212612_lr2.00e-01_bs128_snapshot-pl5[e40].csv, Test Accuracy: 0.6424949169158936, Test ID Accuracy: 0.6566102504730225\n",
      "4. File: resnet-34_20241116-174004_lr2.00e-01_bs128_snapshot-pl3[e60].csv, Test Accuracy: 0.6406720876693726, Test ID Accuracy: 0.6580819487571716\n",
      "\n",
      "MoE Results:\n",
      "1. File: MoE3_resnet-50_resnet-domain-50_20241118-081710_lr1.00e-04_bs128[snap-5_lexp-3-learnMapper].csv, Test Accuracy: 0.6813114881515503, Test ID Accuracy: 0.7001471519470215\n",
      "2. File: MoE5_resnet-50_resnet-domain-50_20241118-152917_lr1.00e-04_bs128[snap-5_lexp-3_learnMapper_uniformInit].csv, Test Accuracy: 0.6789512038230896, Test ID Accuracy: 0.6997792720794678\n",
      "3. File: MoE5_resnet-34_resnet-domain-50_20241116-130542_lr1.00e-03_bs128[learnAllSteep-reworkForward-smaxRouter].csv, Test Accuracy: 0.6476128101348877, Test ID Accuracy: 0.6438557505607605\n",
      "\n",
      "ViT Results:\n",
      "1. File: vit-16_20241113-204439_lr1.00e-04_bs64[nofreeze].csv, Test Accuracy: 0.5618705153465271, Test ID Accuracy: 0.668015718460083\n",
      "2. File: vit-16_20241116-165014_lr1.00e-04_bs64[freeze].csv, Test Accuracy: 0.4482017159461975, Test ID Accuracy: 0.5391219258308411\n"
     ]
    }
   ],
   "source": [
    "def rank_files(file_list):\n",
    "    results = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(csv_dir, file)\n",
    "        try:\n",
    "            # Read the CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Strip whitespace from the 'Unnamed: 0' column\n",
    "            df[\"Unnamed: 0\"] = df[\"Unnamed: 0\"].str.strip()\n",
    "            # Extract accuracy for 'test' and 'id_test' columns\n",
    "            acc_test = df.loc[df[\"Unnamed: 0\"] == \"acc_avg\", \"test\"].values[0]\n",
    "            acc_id_test = df.loc[df[\"Unnamed: 0\"] == \"acc_avg\", \"id_test\"].values[0]\n",
    "            results.append((file, acc_test, acc_id_test))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort files first by 'test' accuracy, then by 'id_test' accuracy\n",
    "    results = sorted(results, key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    return results\n",
    "\n",
    "# Run the updated function\n",
    "ranked_resnet_results = rank_files(resnet_results)\n",
    "ranked_snapshot_ensemble_results = rank_files(snapshot_ensemble_results)\n",
    "ranked_moe_results = rank_files(moe_results)\n",
    "ranked_vit_results = rank_files(vit_results)\n",
    "\n",
    "# Print results\n",
    "results_summary = {\n",
    "    \"ResNet Results\": ranked_resnet_results,\n",
    "    \"Snapshot Ensemble Results\": ranked_snapshot_ensemble_results,\n",
    "    \"MoE Results\": ranked_moe_results,\n",
    "    \"ViT Results\": ranked_vit_results,\n",
    "}\n",
    "\n",
    "# Print the ranked results\n",
    "for category, results in results_summary.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for rank, result in enumerate(results, start=1):\n",
    "        print(f\"{rank}. File: {result[0]}, Test Accuracy: {result[1]}, Test ID Accuracy: {result[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Model  Test Accuracy  Test Recall  Test F1\n",
      "                                       0.721133     0.272167 0.275299\n",
      "                                       0.738193     0.260434 0.266368\n",
      "                                       0.682059     0.223976 0.233204\n",
      "       --- Snapshot Ensemble ---            NaN          NaN      NaN\n",
      "                                       0.677526     0.255944 0.251981\n",
      "                                       0.677315     0.262979 0.257199\n",
      "                                       0.642495     0.227946 0.223529\n",
      "                                       0.640672     0.226629 0.221488\n",
      "--- Mixture of Experts (MoE) ---            NaN          NaN      NaN\n",
      "                                       0.681311     0.266920 0.260069\n",
      "                                       0.647613     0.222860 0.218446\n",
      "                                       0.678951     0.248945 0.245326\n",
      "--- Vision Transformer (ViT) ---            NaN          NaN      NaN\n",
      "                                       0.561871     0.196435 0.169430\n",
      "                                       0.448202     0.098078 0.088369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the CSV files\n",
    "csv_dir = \"/home/hice1/kkang68/scratch/meadow/results/\"\n",
    "\n",
    "# Lists of results\n",
    "resnet_results = [\n",
    "    \"resnet-152_20241103-174623_lr0.0001_bs64.csv\",\n",
    "    \"resnet-50_20241107-111821_lr0.0001_bs64.csv\",\n",
    "    \"resnet-34_20241114-123531_lr1.00e-04_bs128[e40estop7].csv\",\n",
    "]\n",
    "\n",
    "snapshot_ensemble_results = [\n",
    "    \"resnet-50_20241114-232226_lr2.00e-01_bs128_snapshot-pl5[e40].csv\",\n",
    "    \"resnet-50_20241118-130313_lr2.00e-01_bs128_snapshot-pl3[e60].csv\",\n",
    "    \"resnet-34_20241113-212612_lr2.00e-01_bs128_snapshot-pl5[e40].csv\",\n",
    "    \"resnet-34_20241116-174004_lr2.00e-01_bs128_snapshot-pl3[e60].csv\",\n",
    "]\n",
    "\n",
    "moe_results = [\n",
    "    \"MoE3_resnet-50_resnet-domain-50_20241118-081710_lr1.00e-04_bs128[snap-5_lexp-3-learnMapper].csv\",\n",
    "    \"MoE5_resnet-34_resnet-domain-50_20241116-130542_lr1.00e-03_bs128[learnAllSteep-reworkForward-smaxRouter].csv\",\n",
    "    \"MoE5_resnet-50_resnet-domain-50_20241118-152917_lr1.00e-04_bs128[snap-5_lexp-3_learnMapper_uniformInit].csv\",\n",
    "]\n",
    "\n",
    "vit_results = [\n",
    "    \"vit-16_20241113-204439_lr1.00e-04_bs64[nofreeze].csv\",\n",
    "    \"vit-16_20241116-165014_lr1.00e-04_bs64[freeze].csv\",\n",
    "]\n",
    "\n",
    "# Helper function to extract metrics\n",
    "def extract_metrics(file_list, csv_dir):\n",
    "    results = []\n",
    "    for file in file_list:\n",
    "        file_path = os.path.join(csv_dir, file)\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Strip whitespace from the 'Unnamed: 0' column\n",
    "            df[\"Unnamed: 0\"] = df[\"Unnamed: 0\"].str.strip()\n",
    "            # Extract accuracy, recall, and F1 for 'test'\n",
    "            acc_test = df.loc[df[\"Unnamed: 0\"] == \"acc_avg\", \"test\"].values[0]\n",
    "            recall_test = df.loc[df[\"Unnamed: 0\"] == \"recall-macro_all\", \"test\"].values[0]\n",
    "            f1_test = df.loc[df[\"Unnamed: 0\"] == \"F1-macro_all\", \"test\"].values[0]\n",
    "            results.append({\"Model\": file, \"Test Accuracy\": acc_test, \"Test Recall\": recall_test, \"Test F1\": f1_test})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    return results\n",
    "\n",
    "# Extract metrics for each category\n",
    "resnet_metrics = extract_metrics(resnet_results, csv_dir)\n",
    "snapshot_ensemble_metrics = extract_metrics(snapshot_ensemble_results, csv_dir)\n",
    "moe_metrics = extract_metrics(moe_results, csv_dir)\n",
    "vit_metrics = extract_metrics(vit_results, csv_dir)\n",
    "\n",
    "# Combine all metrics into a structured DataFrame\n",
    "rows = []\n",
    "\n",
    "# Add ResNet results\n",
    "rows.extend(resnet_metrics)\n",
    "\n",
    "# Add Snapshot Ensemble results\n",
    "rows.append({\"Model\": \"--- Snapshot Ensemble ---\", \"Test Accuracy\": None, \"Test Recall\": None, \"Test F1\": None})\n",
    "rows.extend(snapshot_ensemble_metrics)\n",
    "\n",
    "# Add MoE results\n",
    "rows.append({\"Model\": \"--- Mixture of Experts (MoE) ---\", \"Test Accuracy\": None, \"Test Recall\": None, \"Test F1\": None})\n",
    "rows.extend(moe_metrics)\n",
    "\n",
    "# Add ViT results\n",
    "rows.append({\"Model\": \"--- Vision Transformer (ViT) ---\", \"Test Accuracy\": None, \"Test Recall\": None, \"Test F1\": None})\n",
    "rows.extend(vit_metrics)\n",
    "\n",
    "# Create DataFrame and format\n",
    "table_df = pd.DataFrame(rows)\n",
    "table_df[\"Model\"] = table_df[\"Model\"].str.replace(r\".*\\.csv\", \"\", regex=True)  # Clean up file names for clarity\n",
    "table_df = table_df.reset_index(drop=True)  # Remove the index column\n",
    "\n",
    "# Format sub-headers to stand out\n",
    "table_df.loc[table_df[\"Model\"].str.contains(\"---\"), [\"Test Accuracy\", \"Test Recall\", \"Test F1\"]] = None\n",
    "\n",
    "# Display the table\n",
    "print(table_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the DataFrame\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet 152\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet 50\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet 34\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     ]\n\u001b[1;32m     39\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    \"Model\": [\n",
    "        \"ResNet 152\", \"ResNet 50\", \"ResNet 34\",\n",
    "        \"Snapshot Ensemble\", \n",
    "        \"SE 50, 3 experts\", \"SE 50, 3 experts\", \"SE 34, 5 experts\", \"SE 34, 3 experts\",\n",
    "        \"Mixture of Experts (MoE)\", \n",
    "        \"MoE 50, 3 experts\", \"MoE 34, 5 experts\", \"MoE 34, 3 experts\",\n",
    "        \"Vision Transformer (ViT)\", \n",
    "        \"ViT 16 No Freeze\", \"ViT 16 Freeze\"\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        0.721133, 0.738193, 0.682059, None,\n",
    "        0.677526, 0.677315, 0.642495, 0.640672,\n",
    "        None,\n",
    "        0.681311, 0.647613, 0.678951,\n",
    "        None,\n",
    "        0.561871, 0.448202\n",
    "    ],\n",
    "    \"Test Recall\": [\n",
    "        0.272167, 0.260434, 0.223976, None,\n",
    "        0.255944, 0.262979, 0.227946, 0.226629,\n",
    "        None,\n",
    "        0.266920, 0.222860, 0.248945,\n",
    "        None,\n",
    "        0.196435, 0.098078\n",
    "    ],\n",
    "    \"Test F1\": [\n",
    "        0.275299, 0.266368, 0.233204, None,\n",
    "        0.251981, 0.257199, 0.223529, 0.221488,\n",
    "        None,\n",
    "        0.260069, 0.218446, 0.245326,\n",
    "        None,\n",
    "        0.169430, 0.088369\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define colors\n",
    "header_color = 'lightblue'\n",
    "subheader_color = 'lightgrey'\n",
    "cell_color = 'white'\n",
    "nan_color = 'white'\n",
    "\n",
    "# Prepare the table for Plotly\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=[\"<b>Model</b>\", \"<b>Test Accuracy</b>\", \"<b>Test Recall</b>\", \"<b>Test F1</b>\"],\n",
    "        fill_color=header_color,\n",
    "        align='center',\n",
    "        font=dict(size=12, color='black')\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[\n",
    "            df[\"Model\"], \n",
    "            df[\"Test Accuracy\"].fillna(''),  # Replace NaN with an empty string\n",
    "            df[\"Test Recall\"].fillna(''),\n",
    "            df[\"Test F1\"].fillna('')\n",
    "        ],\n",
    "        fill_color=[\n",
    "            [subheader_color if \"Snapshot\" in model or \"Mixture\" in model or \"Vision\" in model else cell_color for model in df[\"Model\"]],\n",
    "            cell_color, cell_color, cell_color\n",
    "        ],\n",
    "        align='center',\n",
    "        font=dict(size=11, color='black')\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Show table\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Experimental Results Table\",\n",
    "        x=0.5,\n",
    "        font=dict(size=16)\n",
    "    ),\n",
    "    margin=dict(l=10, r=10, t=30, b=10)\n",
    ")\n",
    "\n",
    "# Export table as an image or HTML\n",
    "fig.write_image(\"results_table_colored.png\")\n",
    "fig.write_html(\"results_table_colored.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
